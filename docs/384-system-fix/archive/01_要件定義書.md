# 📋 384爻システム データベース統合型文脈理解機能 要件定義書

**文書番号**: RD-384-004  
**バージョン**: 4.0（真のデータベース統合版）  
**作成日**: 2025年8月28日  
**作成者**: HAQEI開発チーム  
**承認者**: [未承認]  

---

## 1. プロジェクト概要

### 1.1 背景と現状分析

#### 現状の深刻な問題
現在の384爻システムは以下の致命的な問題を抱えており、真の文脈理解システムからは程遠い状態です：

1. **データベース不在の危機的状況**
   - 全データが単一JSON（koudo_shishin.json）の `shin`/`hen` 2フィールドのみに依存
   - 豊富な利用可能データ（enhanced_hexagrams_complete.json等）が完全に無視されている
   - データ永続化機構が皆無で、フィードバック蓄積不可能

2. **自然言語処理機能の完全欠如**
   - 形態素解析辞書：未導入（IPA辞書、MeCab辞書等）
   - 類義語辞書：未導入（WordNet日本語版等）
   - 意味理解：単純な文字列マッチングのみ

3. **学習・フィードバック機能の不在**
   - ユーザーフィードバック保存先：存在しない
   - 分類精度改善機構：存在しない
   - 過去の分析履歴：保存されない

### 1.2 利用可能データリソースの完全活用方針

#### 既存データ資産の現状
```
利用可能データファイル分析:
├── koudo_shishin.json (386エントリ) - ✅ 現在使用中（shin/henのみ）
├── enhanced_hexagrams_complete.json (384完全データ) - ❌ 完全未使用
├── yaoci_31-63.json - ❌ 完全未使用  
├── h384.json - ❌ 完全未使用
└── 現在のデータ活用率: 約25%（深刻な資源浪費）
```

#### データベース統合戦略
**目標**: 75%の未活用データを包括的データベースシステムで完全統合

| データソース | 統合先DBMS | 用途 | 統合方法 |
|-------------|----------|------|---------|
| enhanced_hexagrams_complete.json | SQLite | 爻辞・意味・性格特性データ | 正規化テーブル設計 |
| yaoci_31-63.json | SQLite | 専門爻辞データ | enhanced_hexagramsと結合 |
| h384.json | SQLite | 384爻基本情報 | メインインデックステーブル |
| koudo_shishin.json | SQLite | 既存shin/henデータ | 既存互換レイヤー維持 |
| IPA辞書（外部調達） | SQLite | 日本語形態素解析 | 50MB辞書データベース |
| WordNet-jp（外部調達） | SQLite | 類義語・意味関係 | 20MB類義語データベース |
| フィードバックデータ | MongoDB | 学習・改善データ | 動的スキーマ対応 |
| 分析キャッシュ | Redis | 高速レスポンス | TTL付きキャッシング |

### 1.3 プロジェクト目標（データベース中心設計）

**基本方針**: JSONファイル依存から脱却し、エンタープライズグレードのデータベース統合システム構築

#### Phase 1: データベース基盤構築（Week 1-2）
- **SQLite統合データベース**: 4つのJSONファイル + 外部辞書の完全統合
- **MongoDB導入**: フィードバック・学習データの永続化システム
- **Redis導入**: 分析結果キャッシュによる高速化
- **データ移行**: 既存データの正規化・インポート

#### Phase 2: 自然言語処理エンジン（Week 3-4）
- **MeCab + IPA辞書**: 日本語形態素解析システム
- **WordNet-jp統合**: 類義語・意味類似性計算
- **インテリジェントスコアリング**: 複合アルゴリズムによる高精度分類

#### Phase 3: 学習・最適化システム（Week 5-6）
- **フィードバックループ**: MongoDB基盤の動的重み調整
- **性能最適化**: Redis活用の3ms以内レスポンス達成
- **継続学習**: 分類精度の月次2%向上システム

---

## 2. データベース設計要件

### 2.1 SQLite統合データベース設計

#### 2.1.1 爻データ統合テーブル
```sql
-- メイン爻テーブル（384爻完全データ）
CREATE TABLE lines_384 (
    line_id INTEGER PRIMARY KEY, -- 1-384
    hexagram_id INTEGER NOT NULL, -- 1-64
    line_position INTEGER NOT NULL, -- 1-6 (初爻-上爻)
    hexagram_name TEXT NOT NULL,
    line_name TEXT NOT NULL,
    
    -- enhanced_hexagrams_complete.json から統合
    yaoci_text TEXT, -- 爻辞
    yaoci_meaning TEXT, -- 爻辞の意味
    personality_trait TEXT, -- 性格特性
    transformation_potential TEXT, -- 変化の可能性
    
    -- yaoci_31-63.json から補完
    extended_yaoci TEXT,
    classical_interpretation TEXT,
    
    -- h384.json から基本情報
    basic_meaning TEXT,
    keywords TEXT, -- JSON array
    
    -- koudo_shishin.json から既存データ（互換性維持）
    shin_data TEXT,
    hen_data TEXT,
    
    created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
    updated_at DATETIME DEFAULT CURRENT_TIMESTAMP
);

-- インデックス設計
CREATE INDEX idx_hexagram_position ON lines_384(hexagram_id, line_position);
CREATE INDEX idx_keywords ON lines_384(keywords);
CREATE UNIQUE INDEX idx_line_id ON lines_384(line_id);
```

#### 2.1.2 形態素解析辞書テーブル（IPA辞書統合）
```sql
-- MeCab IPA辞書データベース化
CREATE TABLE morphology_dict (
    id INTEGER PRIMARY KEY,
    surface TEXT NOT NULL, -- 表層形
    left_context_id INTEGER,
    right_context_id INTEGER,
    cost INTEGER,
    part_of_speech TEXT NOT NULL, -- 品詞
    pos_detail1 TEXT,
    pos_detail2 TEXT,
    pos_detail3 TEXT,
    inflection_type TEXT,
    inflection_form TEXT,
    base_form TEXT, -- 基本形
    reading TEXT, -- 読み
    pronunciation TEXT, -- 発音
    
    -- 易経特化カスタム分類
    yijing_category TEXT, -- 易経用語分類（卦名、爻辞、概念等）
    semantic_weight REAL DEFAULT 1.0
);

-- パフォーマンス最適化インデックス
CREATE INDEX idx_surface ON morphology_dict(surface);
CREATE INDEX idx_base_form ON morphology_dict(base_form);
CREATE INDEX idx_pos ON morphology_dict(part_of_speech);
CREATE INDEX idx_yijing_category ON morphology_dict(yijing_category);
```

#### 2.1.3 類義語辞書テーブル（WordNet-jp統合）
```sql
-- WordNet日本語版データベース化
CREATE TABLE synonym_relations (
    id INTEGER PRIMARY KEY,
    word1 TEXT NOT NULL,
    word2 TEXT NOT NULL,
    relation_type TEXT NOT NULL, -- synonym, hypernym, hyponym, meronym等
    similarity_score REAL NOT NULL, -- Wu-Palmer類似度
    confidence REAL DEFAULT 1.0,
    
    -- 易経ドメイン特化重み
    yijing_relevance REAL DEFAULT 0.0,
    domain_category TEXT -- general, yijing, psychology, leadership等
);

CREATE INDEX idx_word1 ON synonym_relations(word1);
CREATE INDEX idx_word2 ON synonym_relations(word2);
CREATE INDEX idx_relation_similarity ON synonym_relations(relation_type, similarity_score DESC);
CREATE INDEX idx_yijing_relevance ON synonym_relations(yijing_relevance DESC);
```

### 2.2 MongoDB学習データ設計

#### 2.2.1 ユーザーフィードバックコレクション
```javascript
// user_feedback collection schema
{
  _id: ObjectId,
  timestamp: ISODate,
  session_id: String, // ユーザーセッション識別
  
  // 分析入力データ
  user_input: {
    text: String, // 元のユーザー入力
    text_length: Number,
    language: String // "ja", "en" etc.
  },
  
  // システム分析結果
  system_analysis: {
    predicted_line_id: Number, // 1-384
    confidence_score: Number, // 0-1
    processing_time_ms: Number,
    
    // 詳細スコア分解
    component_scores: {
      morphology_score: Number,
      synonym_score: Number,
      yaoci_match_score: Number,
      cache_hit: Boolean
    },
    
    // 使用された特徴量
    extracted_features: {
      morphology_tokens: Array, // 形態素解析結果
      keywords: Array, // 抽出キーワード
      synonyms_matched: Array // マッチした類義語
    }
  },
  
  // ユーザーフィードバック
  user_feedback: {
    correct_line_id: Number, // ユーザーが判断した正解
    accuracy_rating: Number, // 1-5評価
    feedback_text: String, // 自由記述
    feedback_type: String // "correct", "partially_correct", "incorrect"
  },
  
  // 学習メタデータ
  learning_metadata: {
    was_used_for_training: Boolean,
    training_weight: Number,
    feedback_quality_score: Number
  }
}
```

#### 2.2.2 学習統計コレクション
```javascript
// learning_statistics collection schema
{
  _id: ObjectId,
  date: ISODate,
  
  // 日次統計
  daily_metrics: {
    total_queries: Number,
    avg_confidence: Number,
    feedback_count: Number,
    accuracy_improvement: Number // 前日比
  },
  
  // 爻別性能統計
  line_performance: {
    line_id: Number,
    prediction_count: Number,
    accuracy_rate: Number,
    avg_confidence: Number,
    improvement_trend: Array // 過去30日の推移
  },
  
  // 動的重み調整データ
  dynamic_weights: {
    morphology_weight: Number,
    synonym_weight: Number,
    yaoci_weight: Number,
    learning_rate: Number
  }
}
```

### 2.3 Redis キャッシュ設計

#### 2.3.1 キーパターンとTTL戦略
```
分析結果キャッシュ:
analysis:{text_hash}:result (TTL: 1時間)
└── 完全な分析結果をJSON格納

形態素解析キャッシュ:
morphology:{text_hash} (TTL: 24時間)  
└── MeCab解析結果をJSON格納

類義語キャッシュ:
synonyms:{word_hash} (TTL: 12時間)
└── WordNet類義語リストをJSON格納

統計キャッシュ:
stats:daily:{date} (TTL: 7日)
└── 日次統計データをJSON格納

session:{session_id} (TTL: 30分)
└── ユーザーセッション情報
```

---

## 3. 機能要件（データベース統合型）

### 3.1 データベース統合機能

#### FR-DB-001: SQLiteマスターデータベース
**説明**: 4つのJSONファイル + 外部辞書の完全統合データベース

**データ統合要件**:
```yaml
統合対象データ:
  - enhanced_hexagrams_complete.json: 64卦×6爻完全データ
  - yaoci_31-63.json: 専門爻辞データ
  - h384.json: 384爻基本情報
  - koudo_shishin.json: 既存shin/henデータ
  - MeCab IPA辞書: 50MB日本語辞書
  - WordNet-jp: 20MB類義語辞書

データ正規化要件:
  - 重複排除: 100%重複データの統合
  - NULL値処理: デフォルト値またはNULL許可設定
  - インデックス最適化: 検索性能向上
  - 外部キー制約: データ整合性保証
```

**実装コード例**:
```javascript
class SQLiteIntegratedDatabase {
    constructor() {
        this.db = new SQLite3('./dbs/haqei_master.db');
    }
    
    async initializeDatabase() {
        // 1. テーブル作成
        await this.createTables();
        
        // 2. JSONデータ統合
        await this.importEnhancedHexagrams();
        await this.importYaociData();
        await this.importH384Data();
        await this.importKoudoShishin();
        
        // 3. 外部辞書統合
        await this.importIPADictionary();
        await this.importWordNetJp();
        
        // 4. インデックス最適化
        await this.optimizeIndexes();
    }
    
    async importEnhancedHexagrams() {
        const data = JSON.parse(fs.readFileSync('./public/data/enhanced_hexagrams_complete.json'));
        
        const insertStmt = this.db.prepare(`
            INSERT INTO lines_384 (
                line_id, hexagram_id, line_position, hexagram_name, line_name,
                yaoci_text, yaoci_meaning, personality_trait, transformation_potential
            ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
        `);
        
        for (const hexagram of data) {
            for (let pos = 0; pos < 6; pos++) {
                const line = hexagram.six_lines[pos];
                const lineId = (hexagram.number - 1) * 6 + (pos + 1);
                
                insertStmt.run([
                    lineId,
                    hexagram.number,
                    pos + 1,
                    hexagram.name,
                    line.name || `${hexagram.name} ${this.getPositionName(pos + 1)}`,
                    line.text,
                    line.meaning,
                    line.personality_trait,
                    line.transformation_potential
                ]);
            }
        }
        
        insertStmt.finalize();
    }
    
    async searchByMorphology(tokens) {
        const query = `
            SELECT DISTINCT l.*, 
                   COUNT(m.surface) as token_match_count,
                   GROUP_CONCAT(m.surface) as matched_tokens
            FROM lines_384 l
            JOIN morphology_dict m ON (
                l.yaoci_text LIKE '%' || m.surface || '%' OR
                l.yaoci_meaning LIKE '%' || m.base_form || '%' OR
                l.keywords LIKE '%' || m.surface || '%'
            )
            WHERE m.surface IN (${tokens.map(() => '?').join(',')})
            GROUP BY l.line_id
            ORDER BY token_match_count DESC, m.semantic_weight DESC
            LIMIT 20
        `;
        
        return this.db.all(query, tokens.map(t => t.surface));
    }
}
```

**優先度**: 必須

#### FR-DB-002: MongoDB学習データシステム
**説明**: フィードバック・学習データの動的管理システム

**学習データ要件**:
```yaml
フィードバック収集:
  - リアルタイム保存: ユーザー評価の即座記録
  - バッチ処理: 夜間統計計算・重み調整
  - データ品質管理: 不正・偏ったフィードバックの検出

学習アルゴリズム:
  - 動的重み調整: フィードバック基づく係数自動調整
  - 性能追跡: 精度改善トレンド監視
  - A/Bテスト: 新アルゴリズムの段階導入
```

**実装コード例**:
```javascript
class MongoLearningSystem {
    constructor() {
        this.client = new MongoClient('mongodb://localhost:27017');
        this.db = this.client.db('haqei_learning');
    }
    
    async saveFeedback(feedback) {
        const feedbackDoc = {
            ...feedback,
            timestamp: new Date(),
            processed: false,
            quality_score: await this.calculateFeedbackQuality(feedback)
        };
        
        const result = await this.db.collection('user_feedback').insertOne(feedbackDoc);
        
        // リアルタイム学習トリガー
        if (feedbackDoc.quality_score > 0.8) {
            await this.triggerLearning(feedbackDoc);
        }
        
        return result.insertedId;
    }
    
    async triggerLearning(feedback) {
        const { user_input, system_analysis, user_feedback } = feedback;
        
        // 予測が間違っていた場合の重み調整
        if (system_analysis.predicted_line_id !== user_feedback.correct_line_id) {
            await this.adjustWeights({
                input: user_input,
                correct_line: user_feedback.correct_line_id,
                incorrect_prediction: system_analysis.predicted_line_id,
                component_scores: system_analysis.component_scores
            });
        }
        
        // 学習統計の更新
        await this.updateLearningStatistics(feedback);
    }
    
    async adjustWeights(learningData) {
        const currentWeights = await this.getCurrentWeights();
        
        // 簡単な勾配調整（実際はより複雑なアルゴリズム）
        const adjustments = {
            morphology_weight: learningData.component_scores.morphology_score > 0.7 
                ? currentWeights.morphology_weight * 0.98 
                : currentWeights.morphology_weight * 1.02,
            synonym_weight: learningData.component_scores.synonym_score > 0.7 
                ? currentWeights.synonym_weight * 0.98 
                : currentWeights.synonym_weight * 1.02
        };
        
        await this.db.collection('learning_statistics').updateOne(
            { date: new Date().toISOString().split('T')[0] },
            { $set: { dynamic_weights: adjustments } },
            { upsert: true }
        );
    }
}
```

**優先度**: 必須

### 3.2 自然言語処理機能（データベース統合型）

#### FR-NLP-001: MeCab形態素解析システム
**説明**: SQLite統合IPA辞書による高精度日本語解析

**形態素解析要件**:
```yaml
辞書システム:
  - IPA辞書: 標準日本語語彙（約50MB）
  - 易経専門辞書: 卦名・爻辞・専門用語（約2MB）
  - 動的辞書更新: フィードバック基づく新語追加

解析精度目標:
  - 一般文: 95%以上の形態素分割精度
  - 易経用語: 90%以上の専門用語認識率
  - 処理速度: 平均2ms以内
```

**実装コード例**:
```javascript
class DatabaseIntegratedMeCab {
    constructor(sqliteDB) {
        this.mecab = require('mecab-async');
        this.db = sqliteDB;
        this.customDict = new Map();
    }
    
    async analyze(text) {
        // 1. MeCab基本解析
        const tokens = await this.mecab.parse(text);
        
        // 2. SQLite辞書で補完・修正
        const enhancedTokens = await this.enhanceWithDatabase(tokens);
        
        // 3. 易経専門用語の特別処理
        const yijingTokens = await this.processYijingTerms(enhancedTokens);
        
        // 4. キーワード抽出
        const keywords = await this.extractKeywords(yijingTokens);
        
        return {
            tokens: yijingTokens,
            keywords: keywords,
            semantic_categories: await this.categorizeSemantics(keywords),
            processing_time: Date.now() - startTime
        };
    }
    
    async enhanceWithDatabase(tokens) {
        const enhancedTokens = [];
        
        for (const token of tokens) {
            // データベースから詳細情報を取得
            const dbInfo = await this.db.get(`
                SELECT * FROM morphology_dict 
                WHERE surface = ? OR base_form = ?
            `, [token.surface, token.surface]);
            
            if (dbInfo) {
                enhancedTokens.push({
                    ...token,
                    yijing_category: dbInfo.yijing_category,
                    semantic_weight: dbInfo.semantic_weight,
                    enhanced: true
                });
            } else {
                enhancedTokens.push(token);
            }
        }
        
        return enhancedTokens;
    }
    
    async processYijingTerms(tokens) {
        // 易経専門用語の複合語処理
        const yijingPatterns = [
            /^(乾|坤|震|巽|坎|離|艮|兌)(為|山|水|天|地|雷|風|火|澤)/,
            /^(初|九|六|上)(九|六)/,
            /^(爻|卦|彖|象)(辞|傳)/
        ];
        
        const processed = [];
        let i = 0;
        
        while (i < tokens.length) {
            let combined = false;
            
            // 易経専門用語の結合処理
            for (const pattern of yijingPatterns) {
                const text = tokens.slice(i, i + 3).map(t => t.surface).join('');
                if (pattern.test(text)) {
                    processed.push({
                        surface: text,
                        pos: '名詞',
                        yijing_category: 'hexagram_name',
                        semantic_weight: 2.0,
                        combined_tokens: tokens.slice(i, i + 3)
                    });
                    i += 3;
                    combined = true;
                    break;
                }
            }
            
            if (!combined) {
                processed.push(tokens[i]);
                i++;
            }
        }
        
        return processed;
    }
}
```

**優先度**: 必須

#### FR-NLP-002: WordNet類義語システム
**説明**: SQLite統合WordNet-jpによる意味的類似性計算

**類義語システム要件**:
```yaml
類義語データベース:
  - WordNet-jp: 日本語概念辞書（約20MB）
  - 易経ドメイン類義語: 専門用語関係（約1MB）
  - 動的類義語学習: フィードバック基づく関係強化

類似度計算:
  - Wu-Palmer類似度: 概念階層基づく計算
  - コサイン類似度: ベクトル空間での計算
  - ドメイン重み: 易経特化の重み調整
```

**優先度**: 必須

### 3.3 インテリジェント分析エンジン

#### FR-AI-001: 統合スコアリングシステム
**説明**: 複数データソース統合による高精度384爻分類

**スコアリング要件**:
```yaml
統合アルゴリズム:
  - 形態素解析スコア: 25%重み（SQLite辞書ベース）
  - 類義語マッチング: 35%重み（WordNet-jpベース）
  - 爻辞直接マッチ: 20%重み（統合爻データベース）
  - 学習重み: 15%重み（Mongoフィードバック）
  - 文脈スコア: 5%重み（文全体の意味）

精度目標:
  - 分類精度: 85%以上
  - カバー率: 60%以上（384爻中240爻以上使用）
  - レスポンス: 平均3ms以内
```

**実装コード例**:
```javascript
class IntelligentScoringEngine {
    constructor(sqliteDB, mongoDB, redisClient) {
        this.sqlite = sqliteDB;
        this.mongo = mongoDB;
        this.redis = redisClient;
        this.weights = {
            morphology: 0.25,
            synonym: 0.35,
            yaoci: 0.20,
            learning: 0.15,
            context: 0.05
        };
    }
    
    async analyzeText(inputText) {
        const cacheKey = `analysis:${this.hashText(inputText)}`;
        
        // 1. Redisキャッシュ確認
        const cached = await this.redis.get(cacheKey);
        if (cached) {
            return { ...JSON.parse(cached), cache_hit: true };
        }
        
        const startTime = Date.now();
        
        // 2. 形態素解析（SQLite辞書使用）
        const morphologyResult = await this.analyzeMorphology(inputText);
        
        // 3. 各爻に対するスコア計算
        const lineScores = await this.calculateAllLineScores(morphologyResult);
        
        // 4. 最高スコア爻の決定
        const bestMatch = lineScores.reduce((best, current) => 
            current.total_score > best.total_score ? current : best
        );
        
        // 5. 結果構造化
        const result = {
            line_384_id: bestMatch.line_id,
            confidence_score: bestMatch.total_score,
            hexagram_name: bestMatch.hexagram_name,
            line_name: bestMatch.line_name,
            yaoci_text: bestMatch.yaoci_text,
            analysis_breakdown: {
                morphology_score: bestMatch.morphology_score,
                synonym_score: bestMatch.synonym_score,
                yaoci_score: bestMatch.yaoci_score,
                learning_score: bestMatch.learning_score,
                context_score: bestMatch.context_score
            },
            extracted_features: morphologyResult,
            processing_time: Date.now() - startTime,
            cache_hit: false
        };
        
        // 6. Redisキャッシュ保存（1時間TTL）
        await this.redis.setex(cacheKey, 3600, JSON.stringify(result));
        
        return result;
    }
    
    async calculateAllLineScores(morphologyResult) {
        const allLines = await this.sqlite.all(`
            SELECT line_id, hexagram_name, line_name, yaoci_text, yaoci_meaning, keywords
            FROM lines_384
        `);
        
        const lineScores = [];
        
        for (const line of allLines) {
            const scores = await this.calculateLineScore(line, morphologyResult);
            lineScores.push({
                ...line,
                ...scores,
                total_score: 
                    scores.morphology_score * this.weights.morphology +
                    scores.synonym_score * this.weights.synonym +
                    scores.yaoci_score * this.weights.yaoci +
                    scores.learning_score * this.weights.learning +
                    scores.context_score * this.weights.context
            });
        }
        
        return lineScores;
    }
    
    async calculateLineScore(line, morphologyResult) {
        // 1. 形態素解析スコア
        const morphologyScore = await this.calculateMorphologyScore(
            line, morphologyResult.keywords
        );
        
        // 2. 類義語マッチングスコア
        const synonymScore = await this.calculateSynonymScore(
            line, morphologyResult.keywords
        );
        
        // 3. 爻辞直接マッチスコア
        const yaociScore = this.calculateYaociScore(
            line, morphologyResult.tokens
        );
        
        // 4. 学習重みスコア（MongoDB）
        const learningScore = await this.calculateLearningScore(line.line_id);
        
        // 5. 文脈スコア
        const contextScore = await this.calculateContextScore(
            line, morphologyResult
        );
        
        return {
            morphology_score: morphologyScore,
            synonym_score: synonymScore,
            yaoci_score: yaociScore,
            learning_score: learningScore,
            context_score: contextScore
        };
    }
}
```

**優先度**: 必須

---

## 4. 非機能要件（データベース統合型）

### 4.1 性能要件

#### NFR-001: レスポンス時間
- **キャッシュヒット時**: 1ms以内（Redis活用）
- **初回分析時**: 3ms以内（95%tile）
- **複雑分析時**: 5ms以内（99%tile）
- **データベース起動**: 5秒以内

#### NFR-002: データベース性能
- **SQLite読み込み**: 平均0.5ms（インデックス最適化）
- **MongoDB書き込み**: 平均2ms（レプリケーション無し）
- **Redis操作**: 平均0.1ms（メモリ内処理）
- **同時接続**: 100ユーザーまで対応

#### NFR-003: ストレージ・メモリ要件
- **SQLiteデータベース**: 100MB以内（辞書含む）
- **MongoDBストレージ**: 年間1GB成長
- **Redisメモリ**: 200MB以内
- **アプリケーションメモリ**: 500MB以内

### 4.2 品質要件

#### NFR-004: データ整合性
- **ACID準拠**: SQLite WALモード使用
- **レプリケーション**: MongoDB単一インスタンス
- **バックアップ**: 日次自動SQLiteダンプ
- **データ検証**: 起動時整合性チェック

#### NFR-005: 可用性・信頼性
- **稼働率**: 99.5%（月間3.6時間以下のダウンタイム）
- **障害復旧**: 手動復旧（5分以内）
- **データ保護**: 暗号化なし（開発版）
- **監査ログ**: 重要操作のみログ記録

---

## 5. 実装チェックリスト（データベース統合版）

### 5.1 Phase 1: データベース基盤構築

#### SQLite統合データベース
- [ ] **テーブル設計**: lines_384, morphology_dict, synonym_relations
- [ ] **データ統合**: 4つのJSONファイルの正規化インポート
- [ ] **インデックス最適化**: 検索性能向上のためのインデックス作成
- [ ] **IPA辞書導入**: MeCab辞書のSQLite化（50MB）
- [ ] **WordNet-jp導入**: 類義語辞書のSQLite化（20MB）

#### MongoDB学習システム
- [ ] **コレクション設計**: user_feedback, learning_statistics
- [ ] **スキーマ検証**: MongoDB validator設定
- [ ] **インデックス作成**: クエリ性能最適化
- [ ] **初期データ**: 空コレクションの作成確認

#### Redis キャッシュシステム
- [ ] **接続設定**: Redis 6.0+への接続確認
- [ ] **TTL戦略**: キーごとの適切な有効期限設定
- [ ] **メモリ最適化**: maxmemoryポリシー設定
- [ ] **パフォーマンステスト**: 基本操作の性能確認

### 5.2 Phase 2: 自然言語処理エンジン

#### MeCab統合システム
- [ ] **MeCab設定**: IPA辞書との統合確認
- [ ] **カスタム辞書**: 易経専門用語辞書の追加
- [ ] **性能テスト**: 平均2ms以内の解析時間確認
- [ ] **精度評価**: 専門用語認識率90%以上

#### WordNet類義語システム
- [ ] **WordNet-jp導入**: SQLite辞書の正常動作確認
- [ ] **類似度計算**: Wu-Palmer アルゴリズム実装
- [ ] **性能テスト**: 類義語検索の応答時間確認
- [ ] **精度評価**: 類義語マッチング精度測定

### 5.3 Phase 3: 学習・最適化システム

#### フィードバック学習
- [ ] **フィードバック収集**: MongoDB保存の自動化
- [ ] **動的重み調整**: 学習アルゴリズム実装
- [ ] **性能向上確認**: 月次2%改善の測定準備
- [ ] **A/Bテスト**: 新アルゴリズムの段階導入機能

---

## 6. 承認基準

### 6.1 必須合格基準

| 項目 | 合格基準 | 測定方法 |
|------|---------|---------|
| **データ統合** | 4つのJSONファイル100%統合 | SQLiteクエリでの確認 |
| **分類精度** | 85%以上 | 100サンプルの専門家評価 |
| **カバー率** | 60%以上 | 500クエリでの384爻使用率 |
| **レスポンス時間** | 平均3ms以内 | 1000回実行の平均値 |
| **データベース性能** | SQLite 0.5ms, MongoDB 2ms, Redis 0.1ms | 各DB単体性能テスト |

### 6.2 段階別受け入れ基準

#### Phase 1完了基準
- [ ] SQLite: 4JSON + 2辞書の完全統合
- [ ] MongoDB: 基本コレクション作成・動作確認
- [ ] Redis: キャッシュ機能の基本動作

#### Phase 2完了基準  
- [ ] 分類精度: 70%以上（Phase 3で85%目標）
- [ ] NLP精度: 形態素解析90%、類義語85%
- [ ] 処理性能: 平均5ms以内（Phase 3で3ms目標）

#### Phase 3完了基準
- [ ] 最終精度: 85%以上の分類精度達成
- [ ] 学習機能: フィードバック反映機能の動作確認
- [ ] 性能目標: 全ての非機能要件クリア

---

## 7. 承認

| 役割 | 氏名 | 承認日 | 署名 |
|------|------|--------|------|
| プロダクトオーナー | | | |
| データベースアーキテクト | | | |
| 自然言語処理エンジニア | | | |
| 技術リード | | | |

---

**文書管理**
- **重要**: この要件定義書は真のデータベース統合版として設計
- **データ活用**: 75%の未活用データの完全統合
- **実装根拠**: 具体的なDBMS選定・テーブル設計・コード例を含む
- **段階的実装**: 現実的な6週間スケジュールでの段階的導入
- **配布先**: 開発チーム、データベースチーム、QAチーム